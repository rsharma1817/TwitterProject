{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter API 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxfKMsPzSl5A"
      },
      "source": [
        "!pip install tweepy\n",
        "import tweepy\n",
        "\n",
        "!pip install searchtweets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import requests_oauthlib\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DIR = r'/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "keyFile = open(DIR + '/keys.txt', 'r')\n",
        "consumer_key = keyFile.readline().rstrip()\n",
        "consumer_secret = keyFile.readline().rstrip()\n",
        "access_token = keyFile.readline().rstrip()\n",
        "access_token_secret = keyFile.readline().rstrip()\n",
        "bearer_token = keyFile.readline().rstrip()\n",
        "keyFile.close()\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT0-AmDOZInW"
      },
      "source": [
        "!curl --request GET 'https://api.twitter.com/2/tweets/search/recent?query=from:twitterdev' --header 'Authorization: Bearer AAAAAAAAAAAAAAAAAAAAAFCIOQEAAAAAb6gbAdiRNDHRIz1p5%2BdNm47at2c%3Do1ek5MhAAouqJUSxB1faPoOpurlOCmjK7BVrKpFwmESyN9w4GT'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1b5vpa5eodZ"
      },
      "source": [
        "below is a script i copied from here: https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/Full-Archive-Search/full-archive-search.py\n",
        "\n",
        "i think i get what each of these sub-functions is doing.\n",
        "\n",
        "i have changed what the \"main\" function does (compared to the original linked above) by returning instead of printing -- could that be the problem?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9cbsAz2SrTe"
      },
      "source": [
        "## changed the parameters to allow for looping through lists of dates and times\n",
        "def full_archive_search(start, end):\n",
        "  # To set your environment variables in your terminal run the following line:\n",
        "  # export 'BEARER_TOKEN'='<your_bearer_token>'\n",
        "  bearer_token = 'AAAAAAAAAAAAAAAAAAAAAFCIOQEAAAAAb6gbAdiRNDHRIz1p5%2BdNm47at2c%3Do1ek5MhAAouqJUSxB1faPoOpurlOCmjK7BVrKpFwmESyN9w4GT'\n",
        "\n",
        "  search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
        "\n",
        "  # Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
        "  # expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
        "  query_params = {'query': 'Iran nuclear',\n",
        "                  'expansions': 'author_id',\n",
        "                  'tweet.fields': 'author_id,' + 'conversation_id,' + 'created_at',\n",
        "                  'max_results': 500,\n",
        "                  'start_time': start,\n",
        "                  'end_time': end,\n",
        "                  'user.fields': 'verified,' + 'public_metrics'}\n",
        "\n",
        "\n",
        "  def create_headers(bearer_token):\n",
        "      headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "      return headers\n",
        "\n",
        "\n",
        "  def connect_to_endpoint(url, headers, params):\n",
        "      response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
        "      #print(response.status_code)\n",
        "      if response.status_code != 200:\n",
        "          raise Exception(response.status_code, response.text)\n",
        "      return response.json()\n",
        "\n",
        "  ## commented out lines are either the original print(json.dumps()) or lines I used for testing\n",
        "  def main():\n",
        "      headers = create_headers(bearer_token)\n",
        "      json_response = connect_to_endpoint(search_url, headers, query_params)\n",
        "      #return json_response\n",
        "      #print(json.dumps(json_response, indent=4, sort_keys=False))\n",
        "      #print(type(json_response))\n",
        "      return json_response\n",
        "\n",
        "\n",
        "  if __name__ == \"__main__\":\n",
        "      main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH4rg46ffxIp"
      },
      "source": [
        "I still need to work on the looping below, but I have my lists. Every 30 minutes might be too long though."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4qSpptUOzqX"
      },
      "source": [
        "times = ['00:00:00Z', '00:30:00Z', '01:00:00Z', '01:30:00Z', '02:00:00Z', '02:30:00Z', '03:00:00Z', '03:30:00Z', '04:00:00Z', \n",
        "         '04:30:00Z', '05:00:00Z', '05:30:00Z', '06:00:00Z', '06:30:00Z', '07:00:00Z', '07:30:00Z', '08:00:00Z', '08:30:00Z',\n",
        "         '09:00:00Z', '09:30:00Z', '10:00:00Z', '10:30:00Z', '11:00:00Z', '11:30:00Z', '12:00:00Z', '12:30:00Z', '13:00:00Z',\n",
        "         '13:30:00Z', '14:00:00Z', '14:30:00Z', '15:00:00Z', '15:30:00Z', '16:00:00Z', '16:30:00Z', '17:00:00Z', '17:30:00Z',\n",
        "         '18:00:00Z', '18:30:00Z', '19:00:00Z', '19:30:00Z', '20:00:00Z', '20:30:00Z', '21:00:00Z', '21:30:00Z', '22:00:00Z',\n",
        "         '22:30:00Z', '23:00:00Z', '23:30:00Z', '24:00:00Z']\n",
        "\n",
        "dates = ['2013-11-24T', '2014-01-20T', '2015-04-02T', '2015-07-14', '2015-07-20T', '2015-09-17T', '2016-01-16T', '2018-05-08T', '2019-07-01T,', '2019-09-08T']\n",
        "\n",
        "#for time in times:\n",
        " # try:\n",
        " #     statuses = statuses + api.search_full_archive('environment', \"Iran nuclear\" + \" lang:en\", fromDate = date + times[count], toDate = date + times[count + 1],  maxResults=100)\n",
        " #   except:\n",
        "#      statuses = api.search_full_archive('environment', \"Iran nuclear\" + \" lang:en\", fromDate = date + times[count], toDate = date + times[count + 1], maxResults = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDUpG92LgG_q"
      },
      "source": [
        "Testing timestamps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TUOMTogPfw"
      },
      "source": [
        "(dates[4] + times[23])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6xLiCYagKER"
      },
      "source": [
        "Creating a TweetResults object, I think."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmsQNBduYbjk"
      },
      "source": [
        "tweets = full_archive_search(dates[0] + times[0], dates[0] + times[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul-F3EgzgYmc"
      },
      "source": [
        "But I guess not!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwoSupdEzMi4",
        "outputId": "2d6ac336-7d4d-4b98-a86b-cea85ddfd089"
      },
      "source": [
        "type(tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pflu5uBcd8hk"
      },
      "source": [
        "df = pd.read_json(tweets)\n",
        "print(df)\n",
        "#df.to_csv('data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}